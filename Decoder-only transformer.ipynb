{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Decoder-Only Transformer (LLM) For Question Asking\n","\n","\"***FROM SCRATCH***\""]},{"cell_type":"markdown","metadata":{},"source":["### Notebook Structure\n","---\n","**Disclaimer** :\n","- #### Data \n","  - Data source\n","  - Tokenization\n","  - Features and Target\n","  - Test data\n","- #### Model Design\n","  - Positional encoding\n","  - Multi-head attention\n","  - Transformer Decoder\n","  - Final Architecture\n","- #### Training script\n","- #### Simplistic Inference Script\n","- #### Issues and mistakes\n","    - Pre-training with a downstream task\n","    - Not masking Padding layers\n","    - Context window\n","    "]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:54:56.685645Z","iopub.status.busy":"2024-06-03T22:54:56.685139Z","iopub.status.idle":"2024-06-03T22:55:01.202169Z","shell.execute_reply":"2024-06-03T22:55:01.201390Z","shell.execute_reply.started":"2024-06-03T22:54:56.685599Z"},"id":"jrgC3OU6jDTW","trusted":true},"outputs":[],"source":["#necessary imports\n","import numpy as np\n","import pandas as pd\n","import torch\n","import matplotlib.pyplot as plot\n","import torch.nn.functional as F\n","from transformers import AutoTokenizer, AutoModel\n","import random"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:55:01.204251Z","iopub.status.busy":"2024-06-03T22:55:01.203802Z","iopub.status.idle":"2024-06-03T22:55:01.237594Z","shell.execute_reply":"2024-06-03T22:55:01.236764Z","shell.execute_reply.started":"2024-06-03T22:55:01.204224Z"},"id":"u7GcvH47hest","outputId":"571193ab-429e-4da9-b706-6e92fdff31a9","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU is available\n"]}],"source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(\"GPU is available\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU is not available, using CPU\")"]},{"cell_type":"markdown","metadata":{},"source":["## DATA"]},{"cell_type":"markdown","metadata":{},"source":["### Data Source\n","> The data I used for this project is the Stanford Question Ansewring Dataset (SQuAD). SQuAD was prepared such that a question and a context would map to an Answer (Q+C --> A). I modified this the data so that a Context would map to question (C --> Q).\n","\n","**Find my modified data here** = [link to dataset](https://drive.google.com/file/d/1sxDIQPxQUxQ9P12lLHyGydnDyNcNwzS-/view?usp=sharing)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:55:01.239274Z","iopub.status.busy":"2024-06-03T22:55:01.238984Z","iopub.status.idle":"2024-06-03T22:55:03.500775Z","shell.execute_reply":"2024-06-03T22:55:03.499807Z","shell.execute_reply.started":"2024-06-03T22:55:01.239251Z"},"id":"hfaQuyuPjDTa","trusted":true},"outputs":[],"source":["data = pd.read_json('{fill with path to your data}').to_dict(orient='list')"]},{"cell_type":"markdown","metadata":{},"source":["### Tokenization"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:55:03.503059Z","iopub.status.busy":"2024-06-03T22:55:03.502761Z","iopub.status.idle":"2024-06-03T22:55:06.777501Z","shell.execute_reply":"2024-06-03T22:55:06.776707Z","shell.execute_reply.started":"2024-06-03T22:55:03.503035Z"},"id":"gri0eJXbjDTb","outputId":"88a35e1d-d66b-4f84-8356-15ba08f1d96f","trusted":true},"outputs":[],"source":["#bert tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:55:06.778872Z","iopub.status.busy":"2024-06-03T22:55:06.778588Z","iopub.status.idle":"2024-06-03T22:55:06.785332Z","shell.execute_reply":"2024-06-03T22:55:06.784468Z","shell.execute_reply.started":"2024-06-03T22:55:06.778848Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[{'from': 'human',\n","  'value': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'},\n"," {'from': 'gpt', 'value': 'When did Beyonce start becoming popular?'}]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["#Example\n","data['conversation'][0]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:55:06.786822Z","iopub.status.busy":"2024-06-03T22:55:06.786519Z","iopub.status.idle":"2024-06-03T22:55:06.797439Z","shell.execute_reply":"2024-06-03T22:55:06.796566Z","shell.execute_reply.started":"2024-06-03T22:55:06.786799Z"},"id":"rrC0Q415jDTb","trusted":true},"outputs":[],"source":["def tokenize_input(qa):\n","    #1. tokenizing with a max seq length of 300 and padding layers\n","    #2. Adding an <sos> and <eos> token to target values. In this case; [CLS] and [SEP]\n","    seq_length = 300\n","    q_tokens = tokenizer(qa[0]['value'],add_special_tokens=False)['input_ids']\n","    a_tokens = tokenizer(qa[1]['value'],padding=True)['input_ids']\n","\n","\n","    x_tokens = q_tokens + a_tokens[:-1]\n","    y_tokens = q_tokens[1:] + a_tokens\n","\n","    x_pad = [0 for i in range(seq_length-len(x_tokens))]\n","    y_pad = [0 for i in range(seq_length-len(x_tokens))]\n","    final_x = x_tokens + x_pad\n","    final_y = y_tokens + y_pad\n","\n","    return final_x, final_y"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:55:06.799409Z","iopub.status.busy":"2024-06-03T22:55:06.798644Z","iopub.status.idle":"2024-06-03T22:57:01.110546Z","shell.execute_reply":"2024-06-03T22:57:01.109616Z","shell.execute_reply.started":"2024-06-03T22:55:06.799375Z"},"id":"zdKnIEo-jDTd","outputId":"313043b0-2865-4ba5-a705-e2b2af4798ea","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (718 > 512). Running this sequence through the model will result in indexing errors\n"]}],"source":["#tokenizing all data\n","tokens = []\n","targets = []\n","for i in random.sample(data['conversation'],len(data['conversation'])):\n","    try:\n","        x, y = tokenize_input(i)\n","\n","        if len(x) == 300:\n","            tokens.append(x)\n","            targets.append(y)\n","    except:\n","        pass\n","\n","\n","X = torch.IntTensor(tokens)\n","Y = torch.LongTensor(targets)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:57:01.112048Z","iopub.status.busy":"2024-06-03T22:57:01.111725Z","iopub.status.idle":"2024-06-03T22:57:01.118998Z","shell.execute_reply":"2024-06-03T22:57:01.117687Z","shell.execute_reply.started":"2024-06-03T22:57:01.112022Z"},"id":"Yb9IZEXkjDTe","outputId":"f62ce0db-2771-47f5-aa8a-1300103cc43a","trusted":true},"outputs":[{"data":{"text/plain":["(torch.Size([124975, 300]), torch.Size([124975, 300]))"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["X.shape, Y.shape"]},{"cell_type":"markdown","metadata":{},"source":["## Test Data"]},{"cell_type":"markdown","metadata":{},"source":["#### **Create your test data here**"]},{"cell_type":"markdown","metadata":{"id":"A0KVqIfujDTf"},"source":["# Model Design"]},{"cell_type":"markdown","metadata":{},"source":["## Important Notes\n","- **Embedding layer:** I used the emmbedding layer from the bert model.\n","- **Positional encoding:** Sinusoidal encoding from Attention is all you need\n","- **Attention:** Multihead (4 heads)\n","- **Linear projection:** Projected input to 224 before passing it through decoder\n","- **Number of decoders:** 8"]},{"cell_type":"markdown","metadata":{"id":"BuyFf4OpjDTh"},"source":["![image](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6133c18-bfaf-4578-8c5a-e5ac7809f65b_1632x784.png)"]},{"cell_type":"markdown","metadata":{},"source":["### Embedding layer"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:57:01.121016Z","iopub.status.busy":"2024-06-03T22:57:01.120698Z","iopub.status.idle":"2024-06-03T22:57:01.130631Z","shell.execute_reply":"2024-06-03T22:57:01.129502Z","shell.execute_reply.started":"2024-06-03T22:57:01.120974Z"},"id":"TgRj0-hnHWRL","trusted":true},"outputs":[],"source":["class embed(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.embedder = AutoModel.from_pretrained('bert-base-uncased')\n","\n","    def forward(self,x_tokens):\n","        inputs = {'input_ids':x_tokens}\n","        with torch.no_grad():\n","            attention_mask = (inputs['input_ids'] != 0).int()\n","            outputs = self.embedder(**inputs,attention_mask=attention_mask)\n","            embeddings = outputs.last_hidden_state * attention_mask.unsqueeze(-1)\n","        return embeddings\n"]},{"cell_type":"markdown","metadata":{},"source":["### Positional Encoding"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:57:01.134146Z","iopub.status.busy":"2024-06-03T22:57:01.133839Z","iopub.status.idle":"2024-06-03T22:57:01.148144Z","shell.execute_reply":"2024-06-03T22:57:01.147270Z","shell.execute_reply.started":"2024-06-03T22:57:01.134121Z"},"id":"hvsscGcfjDTj","trusted":true},"outputs":[],"source":["## sinusoidal positional encoding\n","\n","class pos_enc(torch.nn.Module):\n","    def __init__(self) -> None:\n","        super().__init__()\n","\n","    def forward(self,x):\n","        batch_size, max_seq_length, dmodel = x.shape\n","        pe = torch.zeros_like(x) #position encoding matrix\n","\n","        # Compute the positional encoding values\n","        for pos in range(max_seq_length):\n","            for i in range(0, dmodel):\n","                if i % 2 == 0:\n","                    pe[:, pos, i] = torch.math.sin(pos / (10000 ** (2 * i / dmodel)))\n","                else:\n","                    pe[:, pos, i] = torch.math.cos(pos / (10000 ** (2 * i / dmodel)))\n","\n","        x = x + pe\n","        return x\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Self-attention mechanisim"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:57:01.149495Z","iopub.status.busy":"2024-06-03T22:57:01.149235Z","iopub.status.idle":"2024-06-03T22:57:01.180054Z","shell.execute_reply":"2024-06-03T22:57:01.179141Z","shell.execute_reply.started":"2024-06-03T22:57:01.149473Z"},"id":"pgkDDykdjDTk","trusted":true},"outputs":[],"source":["class self_attention(torch.nn.Module):\n","        def __init__(self,no_of_heads: int ,shape: tuple, mask: bool=False, QKV: list=[]):\n","                '''\n","        Initializes a Self Attention module as described in the \"Attention is all you need\" paper.\n","        This module splits the input into multiple heads to allow the model to jointly attend to information\n","        from different representation subspaces at different positions. After attention is applied independently\n","        on each head, the module concatenates and linearly transforms the results.\n","\n","\n","\n","\n","        ## Parameters:\n","            * no_of_heads (int): Number of attention heads. To implement single head attention, set this parameter to 1. ,i.e, no_of_heads = 1\n","\n","           * shape (tuple): A tuple (seq_length, dmodel) where `seq_length` is the length of the input sequence,\n","                           and `dmodel` is the dimensionality of the input feature space.\n","\n","            * mask (bool, optional): If True, a mask will be applied to prevent attention to future positions. This is particularly useful in decoder layers to ensure that the predictions for a sequence position can depend only on the known outputs at previous positions. Defaults to False.\n","\n","            * QKV (list, optional): A list containing pre-computed Query (Q), Key (K), and Value (V) matrices. If provided, these matrices will be used instead of computing `Q`, `K`, and `V` from the input tensor. This is useful for operations where `Q`, `K`, and `V` come from different sources, such as in cross-attention in the Transformer decoder. The list should contain three tensors of shape (batch_size, seq_length, dmodel), corresponding to Q, K, and V, respectively.\n","        The forward pass computes the multi-head attention for input `x` and returns the transformed output.\n","                '''\n","                super().__init__()\n","                self.h = no_of_heads\n","                self.seq_length,self.dmodel = shape\n","                self.dk = self.dmodel//self.h\n","                self.softmax = torch.nn.Softmax(dim=-1)\n","                self.mQW = torch.nn.ModuleList([torch.nn.Linear(self.dmodel,self.dk) for i in range(self.h)])\n","                self.mKW = torch.nn.ModuleList([torch.nn.Linear(self.dmodel,self.dk) for i in range(self.h)])\n","                self.mVW = torch.nn.ModuleList([torch.nn.Linear(self.dmodel,self.dk) for i in range(self.h)])\n","                self.output_linear = torch.nn.Linear(self.dmodel,self.dmodel)\n","                self.mask = mask\n","                self.QKV = QKV\n","\n","        def __add_mask(self,atten_values):\n","              #masking attention values\n","              mask_value = -1e9\n","              mask = torch.triu(torch.ones(atten_values.shape) * mask_value, diagonal=1)\n","              masked = atten_values + mask.to(device)\n","              return masked\n","\n","        def forward(self, x):\n","            heads = []\n","            for i in range(self.h):\n","                # Apply linear projections in batch from dmodel => h x d_k\n","                if self.QKV:\n","                      q = self.mQW[i](self.QKV[0])\n","                      k = self.mKW[i](self.QKV[1])\n","                      v = self.mVW[i](self.QKV[2])\n","                else:\n","                        q = self.mQW[i](x)\n","                        k = self.mKW[i](x)\n","                        v = self.mVW[i](x)\n","\n","\n","                # Calculate attention using the projected vectors q, k, and v\n","                self.scores = torch.matmul(q, k.transpose(-1, -2)) / torch.sqrt(torch.tensor(self.dk, dtype=torch.float32))\n","                if self.mask:\n","                      self.scores = self.__add_mask(self.scores)\n","\n","\n","                attn = self.softmax(self.scores)\n","                head_i = torch.matmul(attn, v)\n","\n","                heads.append(head_i)\n","\n","            # Concatenate all the heads together\n","            multi_head = torch.cat(heads, dim=-1)\n","            # Final linear layer\n","            output = self.output_linear(multi_head)\n","\n","            return output + x  # Residual connection"]},{"cell_type":"markdown","metadata":{"id":"Q-Zbs4-SjDTm"},"source":["### Decoder"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:57:01.181602Z","iopub.status.busy":"2024-06-03T22:57:01.181232Z","iopub.status.idle":"2024-06-03T22:57:01.193424Z","shell.execute_reply":"2024-06-03T22:57:01.192560Z","shell.execute_reply.started":"2024-06-03T22:57:01.181571Z"},"id":"xUJJvgeJjDTm","trusted":true},"outputs":[],"source":["\n","class decoder_layer(torch.nn.Module):\n","    def __init__(self,shape: tuple,no_of_heads:int = 1):\n","        '''\n","        Implementation of Transformer Dencoder\n","        Parameters:\n","            shape (tuple): The shape (H, W) of the input tensor\n","            no_of_heads (int): number of heads in the attention mechanism. set this to 1 for single head attntion. default = 1\n","        Returns:\n","            Tensor: The output of the encoder layer after applying attention, feedforward network, and normalization.\n","        '''\n","        super().__init__()\n","\n","        self.max_seq_length,self.dmodel = shape\n","        def ff_weights():\n","            layer1 =  torch.nn.Linear(self.dmodel,600)\n","            layer2 = torch.nn.Linear(600,600)\n","            layer3 = torch.nn.Linear(600,self.dmodel)\n","            return layer1,layer2,layer3\n","\n","        self.no_of_heads = no_of_heads\n","\n","        self.multi_head =  self_attention(no_of_heads=no_of_heads, mask=True,\n","                                                    shape=(self.max_seq_length,self.dmodel))\n","\n","        self.layer1,self.layer2,self.layer3 = ff_weights()\n","        self.softmax = torch.nn.Softmax(dim=-1)\n","        self.layerNorm = torch.nn.LayerNorm(shape)\n","        self.relu1 = torch.nn.ReLU()\n","        self.relu2 = torch.nn.ReLU()\n","\n","    def feed_forward(self,x):\n","        f = self.layer1(x)\n","        f = self.relu1(f)\n","        f = self.layer2(f)\n","        f = self.relu2(f)\n","        f = self.layer3(f)\n","\n","        return self.layerNorm(f  + x) #residual connection\n","\n","    def forward(self,x):\n","        x = self.multi_head(x)\n","        x = self.layerNorm(x)\n","        x = self.feed_forward(x)\n","        x = self.layerNorm(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["### Full Model Architecture"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:57:01.194791Z","iopub.status.busy":"2024-06-03T22:57:01.194560Z","iopub.status.idle":"2024-06-03T22:57:01.207213Z","shell.execute_reply":"2024-06-03T22:57:01.206357Z","shell.execute_reply.started":"2024-06-03T22:57:01.194771Z"},"id":"SmtFTuCSjDTn","trusted":true},"outputs":[],"source":["class architecture(torch.nn.Module):\n","    def __init__(self,n_classes,shape) -> None:\n","        super().__init__()\n","        self.max_seq_length,self.dmodel = shape\n","        self.projected_dmodel = 224\n","        self.embedding_layer = embed()\n","        self.proj_to_224 = torch.nn.Linear(self.dmodel, self.projected_dmodel)\n","        self.positional = pos_enc()\n","        self.decoder1 = decoder_layer(shape=(self.max_seq_length,self.projected_dmodel), no_of_heads=8)\n","        self.decoder2 = decoder_layer(shape=(self.max_seq_length,self.projected_dmodel), no_of_heads=8)\n","        self.decoder3 = decoder_layer(shape=(self.max_seq_length,self.projected_dmodel), no_of_heads=8)\n","        self.decoder4 = decoder_layer(shape=(self.max_seq_length,self.projected_dmodel), no_of_heads=8)\n","        self.decoder5 = decoder_layer(shape=(self.max_seq_length,self.projected_dmodel), no_of_heads=8)\n","        self.decoder6 = decoder_layer(shape=(self.max_seq_length,self.projected_dmodel), no_of_heads=8)\n","        self.decoder7 = decoder_layer(shape=(self.max_seq_length,self.projected_dmodel), no_of_heads=8)\n","        self.decoder8 = decoder_layer(shape=(self.max_seq_length,self.projected_dmodel), no_of_heads=8)\n","        # self.decoder5 = decoder_layer(shape=(self.max_seq_length,self.projected_dmodel))\n","        self.final_MLP = torch.nn.Linear(self.projected_dmodel,n_classes)\n","        self.softmax = torch.nn.Softmax(dim=2)\n","\n","    def forward(self,x,temperature=1.0):\n","        x = self.embedding_layer(x)\n","        x = self.proj_to_224(x)\n","        x = self.positional(x)\n","        x = self.decoder1(x)\n","        x = self.decoder2(x)\n","        x = self.decoder3(x)\n","        x = self.decoder4(x)\n","        x = self.decoder5(x)\n","        x = self.decoder6(x)\n","        x = self.decoder7(x)\n","        x = self.decoder8(x)\n","        x = self.final_MLP(x)\n","        logits = x / temperature\n","        x = self.softmax(logits)\n","\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"dM4rxYmZjDTo"},"source":["# Training Script"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T15:16:31.037697Z","iopub.status.busy":"2024-06-03T15:16:31.037333Z","iopub.status.idle":"2024-06-03T15:16:43.367003Z","shell.execute_reply":"2024-06-03T15:16:43.365937Z","shell.execute_reply.started":"2024-06-03T15:16:31.037668Z"},"id":"vAAvP-q8Ny0Q","outputId":"726e2c00-fe19-4cf8-bcf1-35f564659e2d","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.3.2)\n","Requirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.26.4)\n","Requirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.1.2)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (0.11.2)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.0.3)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>17.1->torchmetrics) (3.1.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2024.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"]}],"source":["!pip install torchmetrics"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:57:01.208624Z","iopub.status.busy":"2024-06-03T22:57:01.208296Z","iopub.status.idle":"2024-06-03T22:57:02.982965Z","shell.execute_reply":"2024-06-03T22:57:02.982197Z","shell.execute_reply.started":"2024-06-03T22:57:01.208594Z"},"id":"LPVQfcROjDTp","trusted":true},"outputs":[],"source":["from torchmetrics import Accuracy\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:57:02.984427Z","iopub.status.busy":"2024-06-03T22:57:02.984083Z","iopub.status.idle":"2024-06-03T22:57:02.990683Z","shell.execute_reply":"2024-06-03T22:57:02.989758Z","shell.execute_reply.started":"2024-06-03T22:57:02.984396Z"},"id":"TzgeHiUtjDT3","trusted":true},"outputs":[],"source":["dataset = torch.utils.data.TensorDataset(X,Y)\n","loader = torch.utils.data.DataLoader(dataset,batch_size=20,num_workers=0,shuffle=False)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:57:02.991928Z","iopub.status.busy":"2024-06-03T22:57:02.991692Z","iopub.status.idle":"2024-06-03T22:57:11.429999Z","shell.execute_reply":"2024-06-03T22:57:11.429071Z","shell.execute_reply.started":"2024-06-03T22:57:02.991907Z"},"id":"TLSS-fiMAZn6","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08eb2c3d0c8449c89b7671fd6ffaba07","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["vocab_size = tokenizer.vocab_size\n","model = architecture(n_classes = vocab_size, shape = (300,768))\n","model = model.to(device)\n","model.load_state_dict(torch.load(\"{fill with path to model weights if any}\"))"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T15:18:09.105337Z","iopub.status.busy":"2024-06-03T15:18:09.105018Z","iopub.status.idle":"2024-06-03T15:18:09.118123Z","shell.execute_reply":"2024-06-03T15:18:09.117264Z","shell.execute_reply.started":"2024-06-03T15:18:09.105311Z"},"id":"9H3y3i3mjDT4","trusted":true},"outputs":[],"source":["metric =  Accuracy(num_classes=vocab_size,task='multiclass').to(device)\n","optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n","criterion = torch.nn.CrossEntropyLoss(ignore_index=0,label_smoothing=0.01)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T15:23:13.054072Z","iopub.status.busy":"2024-06-03T15:23:13.053284Z"},"id":"5fK1GD-NjDT4","outputId":"f03d9a8d-ca5c-4783-e8bb-3771d0e3aa51","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Started\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1:  66%|██████▋   | 2770/4166 [1:58:07<1:00:08,  2.59s/it, Loss=9.89, Accuracy=0.234]"]}],"source":["from tqdm import tqdm\n","\n","print('Training Started')\n","NUM_EPOCHS = 1\n","\n","for epoch in range(NUM_EPOCHS):\n","    model.train()  # Set the model to training mode\n","    running_loss = 0.0\n","    epoch_accuracy = 0.0\n","    num_batches = len(loader)\n","\n","    # Initialize tqdm progress bar\n","    with tqdm(total=num_batches, desc=f\"Epoch {epoch + 1}\", leave=True) as pbar:\n","        for i, (x_batch, y_batch) in enumerate(loader):\n","            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","\n","            # Zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            outputs = model(x_batch)\n","            # Flatten the outputs and y_batch tensors one dimension lower\n","            outputs = outputs.view(-1, outputs.shape[-1])\n","            y_batch = y_batch.view(-1)\n","            \n","            # Loss calculation\n","            loss = criterion(outputs, y_batch).to(device)\n","\n","            # Backward pass and optimize\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Metrics\n","            argmax_pred = outputs.argmax(axis=1)\n","            metric.update(argmax_pred, y_batch)\n","\n","            # Print statistics\n","            running_loss += loss.item()\n","            if i % 10 == 9:    # update every 10 mini-batches\n","                accuracy = metric.compute().item()\n","                epoch_accuracy += accuracy\n","                pbar.set_postfix({'Loss': running_loss / (i + 1), 'Accuracy': accuracy})\n","            \n","            # Update the progress bar\n","            pbar.update(1)\n","\n","            # Save model weights periodically\n","            if i % 10 == 9:\n","                torch.save(model.state_dict(), '/kaggle/working/model_weights.pth')\n","\n","    # Compute and print average loss and accuracy for the epoch\n","    avg_loss = running_loss / num_batches\n","    avg_accuracy = epoch_accuracy / (num_batches // 10)  # since we're summing accuracy every 10 batches\n","    print(f'Epoch {epoch + 1} - Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.4f}')\n","\n","print('Training Completed')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-01T18:05:43.457115Z","iopub.status.idle":"2024-06-01T18:05:43.457553Z","shell.execute_reply":"2024-06-01T18:05:43.457346Z","shell.execute_reply.started":"2024-06-01T18:05:43.457328Z"},"trusted":true},"outputs":[],"source":["#Link to download model\n","from IPython.display import FileLink\n","FileLink(r'model_weights.pth')"]},{"cell_type":"markdown","metadata":{"id":"w8X1iQZtjDT4"},"source":["# Simplistic Inference Script"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:58:49.003849Z","iopub.status.busy":"2024-06-03T22:58:49.003254Z","iopub.status.idle":"2024-06-03T22:58:49.008887Z","shell.execute_reply":"2024-06-03T22:58:49.007851Z","shell.execute_reply.started":"2024-06-03T22:58:49.003819Z"},"trusted":true},"outputs":[],"source":["text = '''Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'''"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:58:49.139061Z","iopub.status.busy":"2024-06-03T22:58:49.138244Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["QUESTION FROM THE MODEL:  what is the name of the singer? [SEP]\n"]}],"source":["def model_pred(tokens,temp):\n","    model.eval()\n","    with torch.no_grad():\n","        pred = model(tokens,temp)\n","        pred = pred.view(-1, pred.shape[-1]).argmax(axis=1)\n","    return pred\n","\n","def tokenize_text(text):\n","    seq_length = 300\n","    q_tokens = tokenizer(text,add_special_tokens=False)['input_ids']\n","    pad = [0 for i in range(seq_length-len(q_tokens))]\n","    final_tokens = [q_tokens + pad]\n","    last_index = len(q_tokens)-1\n","    \n","    return torch.tensor(final_tokens),last_index\n","\n","def inference(text, starter='', temperature=1.0):\n","    curr = 0\n","    pred_list = []\n","    t, last_token = tokenize_text(text + '[CLS]' + starter)\n","    t = t.to(device)\n","    \n","    while curr != 102:\n","        print('\\n',\"Generating...\")\n","        all_pred = model_pred(t, temperature)\n","        pred = all_pred[last_token].item()\n","        pred_list.append(pred)\n","        t[0][last_token + 1] = pred\n","        last_token += 1\n","        curr = pred\n","        \n","        if curr > 10:\n","            break\n","    print(\"Question from the model: \".upper(), starter + ' ' + tokenizer.decode(pred_list),'\\n')\n","\n","    return starter + ' ' + tokenizer.decode(pred_list)\n","\n","inference(text, '')\n","\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T15:04:20.910872Z","iopub.status.busy":"2024-06-03T15:04:20.910410Z","iopub.status.idle":"2024-06-03T15:04:20.921567Z","shell.execute_reply":"2024-06-03T15:04:20.920558Z","shell.execute_reply.started":"2024-06-03T15:04:20.910839Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'in some countries, the personal copying exemption explicitly requires that the content being copied was obtained legitimately – i. e., from authorized sources, not file - sharing networks. other countries, such as the netherlands, make no such distinction ; the exemption there had been assumed, even by the government, to apply to any such copying, even from file - sharing networks. however, in april 2014, the court of justice of the european union ruled that \" national legislation which makes no distinction between private copies made from lawful sources and those made from counterfeited or pirated sources cannot be tolerated. \" thus, in the netherlands, for example, downloading from file - sharing networks is no longer legal. [CLS] what does the personal copying exemption explicitly need? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(X[1:2][0])"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T15:04:14.215268Z","iopub.status.busy":"2024-06-03T15:04:14.214853Z","iopub.status.idle":"2024-06-03T15:04:16.101027Z","shell.execute_reply":"2024-06-03T15:04:16.100091Z","shell.execute_reply.started":"2024-06-03T15:04:14.215212Z"},"id":"ylue4m8ujDT5","outputId":"4f9c14ab-18fe-47c2-a7f3-e53c53f6bb99","trusted":true},"outputs":[{"data":{"text/plain":["'the areas, the death use act is is that the data that used was not forly, that.,., from, witnesses, not light - in system. other states, including as the united, have a other relationship, the act in had been been, as as the government, to have to a other use, including from public - in system. in, in september 2011, the school of state of the united union was that \" the law which is more fact from death witnesses from from non forces and the that from non -ed and nond species is be be. \" for, in the united, for example, theing from non - in system is not more a. [CLS] what has the national use act have have? [SEP] the - many - - - - - people. - state [CLS] many the [CLS] [CLS].. to the in -.. the -er the many. [SEP] the [CLS] [SEP] what the the number to. power in s\\'power. -azi [SEP] - - -. - -\\'[SEP] the power the in [SEP] the government [SEP] power - [CLS] the [SEP] - population church %, in - the - power power - of - aser power power of power - as power the thely power in in iner power\\'as to power power [SEP] power the of the east - of not. the \\'. -s\\'was of population of - war the. was to was [CLS].. [SEP]. was [SEP]\\'- [SEP] [SEP] the [SEP] [SEP]'"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["pred = model(X[1:2].to(device))\n","tokens = pred.view(-1, pred.shape[-1]).argmax(axis=1)\n","tokenizer.decode(tokens)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-01T18:05:43.468755Z","iopub.status.idle":"2024-06-01T18:05:43.469127Z","shell.execute_reply":"2024-06-01T18:05:43.468945Z","shell.execute_reply.started":"2024-06-01T18:05:43.468930Z"},"id":"J59cvKfcc73h","outputId":"657d8ae8-78fd-42a5-dde9-8729dfe767bb","trusted":true},"outputs":[],"source":["model(X[1:2].to(device),temperature = 0.2).view(-1, outputs.shape[-1]).argmax(axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-01T18:05:43.470262Z","iopub.status.idle":"2024-06-01T18:05:43.470608Z","shell.execute_reply":"2024-06-01T18:05:43.470449Z","shell.execute_reply.started":"2024-06-01T18:05:43.470435Z"},"id":"H14-KV80jDT6","trusted":true},"outputs":[],"source":["torch.argmax(model(X[:3].to(device)),dim=1)"]},{"cell_type":"markdown","metadata":{},"source":["# Issues\n","\n","- **Not Enough data:** I trained on only 130K samples which is too small\n","- **Pre-trainig on a downstream task:** Pretraining is supposed to be self supervised\n","- **Not masking the padding tokens**\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4831101,"sourceId":8164676,"sourceType":"datasetVersion"},{"modelInstanceId":40759,"sourceId":48742,"sourceType":"modelInstanceVersion"},{"modelInstanceId":44902,"sourceId":53523,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0cbae0a2b5e5488783bbf5b254bc92ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f6663db693f49f8bbcb7eca1555da38":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1503b83375d448c1a49b572d4c436a8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15d4ca8a4b194b6c9ccb41d340cc9766":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cfdf724916a40a891b810221b360393":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15d4ca8a4b194b6c9ccb41d340cc9766","placeholder":"​","style":"IPY_MODEL_fc011fc9aca44c4c9c89828a9cfc3b23","value":" 440M/440M [00:02&lt;00:00, 216MB/s]"}},"26ea50972d63481bb50c60e6e7a2dbe6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"274f1071d4424b5dacd4f15548e448c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8a7a26a303e441b9e904a2c16f25a54","placeholder":"​","style":"IPY_MODEL_0cbae0a2b5e5488783bbf5b254bc92ff","value":"tokenizer_config.json: 100%"}},"289f044f9e14424e8f2ab07ab2f3a651":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3aeb47270404b279ab7c57d85dbef69","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_77f1875173f44bb0850b0e7cb72ef41d","value":570}},"28d68ad4e20a4bd3aefd1121bd3e819b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ad59bfb8c7140dbad51fb0fd8ed622e","placeholder":"​","style":"IPY_MODEL_6d51d9165a784fffae48bc37e63281d7","value":" 232k/232k [00:00&lt;00:00, 3.16MB/s]"}},"2ad59bfb8c7140dbad51fb0fd8ed622e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3403c9cec4784bfea5231cab0cf165a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3711b0e9a2b8474d80c75b104d738b5c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"390ed31ed34b4a22be9bc18391d174e6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44a9175bfc5e4c7f9dcdb16170078874":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48698f31b445414e9b4f68a3879e0d94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49ccfdc933ae416293b3ead357abdef2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4da29bb1507c4b189bcc83faf6a4b22b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4eb9bb2250be4d23b93b94c316143b73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_274f1071d4424b5dacd4f15548e448c2","IPY_MODEL_de115440e1cc4e188a94fa87a6b6c504","IPY_MODEL_7827b192dde24d00a7618cedb9db8e20"],"layout":"IPY_MODEL_daefcfaa39bf4979851a26b5b6ec7dc7"}},"4f0feaf7e9a44733a7beaf873e433d02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bd5152002294a06bb49464de2a96716","placeholder":"​","style":"IPY_MODEL_a7dd233424ae4966b2027d9a5b4af5bc","value":"model.safetensors: 100%"}},"53c34611a1f14f4fa7fa6d3dff5b3fca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7548481727c04c99b9f8100604d4f613","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93f33f7adc0d4f4b814968fd3d229a81","value":466062}},"5a935b86c3944e7480c6a40355c88f92":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ebdcbaffa5994bdabe04494b6b999bbb","IPY_MODEL_289f044f9e14424e8f2ab07ab2f3a651","IPY_MODEL_da514bf0fe3b4a75885a96ef52e82ae1"],"layout":"IPY_MODEL_44a9175bfc5e4c7f9dcdb16170078874"}},"60fac5dd0ed746d499d38fbc2a20059c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bd5152002294a06bb49464de2a96716":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d51d9165a784fffae48bc37e63281d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70b5da641074463e9e224bce7480dde1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7548481727c04c99b9f8100604d4f613":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77f1875173f44bb0850b0e7cb72ef41d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7827b192dde24d00a7618cedb9db8e20":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_390ed31ed34b4a22be9bc18391d174e6","placeholder":"​","style":"IPY_MODEL_880f78f566a54c1da12012f29a337025","value":" 48.0/48.0 [00:00&lt;00:00, 2.31kB/s]"}},"7b1dde817de84efeb5132fbf53f6052c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"880f78f566a54c1da12012f29a337025":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"888284b2884c4550a893f841b78fe587":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ab0218ece9745eeab120735971a91c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f47f417016d24dad99c89001c9f545aa","IPY_MODEL_e69fee4098b74650872933419a00290b","IPY_MODEL_28d68ad4e20a4bd3aefd1121bd3e819b"],"layout":"IPY_MODEL_60fac5dd0ed746d499d38fbc2a20059c"}},"93f33f7adc0d4f4b814968fd3d229a81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9963e0021d4b407a9edd29d74c6b399a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a1779ca4e6be4c498d7412b7cd0a35b2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a362df1263904c47b512f5bb57d7bbb2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7dd233424ae4966b2027d9a5b4af5bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab0043e29386479a8ab0d399de40d8e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f0feaf7e9a44733a7beaf873e433d02","IPY_MODEL_b623724810f84341b347034383542a5c","IPY_MODEL_1cfdf724916a40a891b810221b360393"],"layout":"IPY_MODEL_3711b0e9a2b8474d80c75b104d738b5c"}},"b2f8b5ab3ad14fd9a36bb4bf2c51cc78":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b623724810f84341b347034383542a5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1779ca4e6be4c498d7412b7cd0a35b2","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9963e0021d4b407a9edd29d74c6b399a","value":440449768}},"b9351420cb0c4389b049c0bcdbd42239":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3aeb47270404b279ab7c57d85dbef69":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cecd3a1cc56e41608006fbb6417f2cb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ebae6e20ff414834b1e5cb33cc16949c","IPY_MODEL_53c34611a1f14f4fa7fa6d3dff5b3fca","IPY_MODEL_fa39098a82c84fbdb9b747ecd91b9aed"],"layout":"IPY_MODEL_888284b2884c4550a893f841b78fe587"}},"da514bf0fe3b4a75885a96ef52e82ae1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70b5da641074463e9e224bce7480dde1","placeholder":"​","style":"IPY_MODEL_b2f8b5ab3ad14fd9a36bb4bf2c51cc78","value":" 570/570 [00:00&lt;00:00, 30.8kB/s]"}},"daefcfaa39bf4979851a26b5b6ec7dc7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de115440e1cc4e188a94fa87a6b6c504":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eddd9b70e81c40258271bf1bd530aab6","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f6663db693f49f8bbcb7eca1555da38","value":48}},"e3e37acb6d5f4bd3b5575230de9a229f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e69fee4098b74650872933419a00290b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3e37acb6d5f4bd3b5575230de9a229f","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b9351420cb0c4389b049c0bcdbd42239","value":231508}},"ebae6e20ff414834b1e5cb33cc16949c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4da29bb1507c4b189bcc83faf6a4b22b","placeholder":"​","style":"IPY_MODEL_48698f31b445414e9b4f68a3879e0d94","value":"tokenizer.json: 100%"}},"ebdcbaffa5994bdabe04494b6b999bbb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26ea50972d63481bb50c60e6e7a2dbe6","placeholder":"​","style":"IPY_MODEL_1503b83375d448c1a49b572d4c436a8b","value":"config.json: 100%"}},"eddd9b70e81c40258271bf1bd530aab6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f47f417016d24dad99c89001c9f545aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a362df1263904c47b512f5bb57d7bbb2","placeholder":"​","style":"IPY_MODEL_7b1dde817de84efeb5132fbf53f6052c","value":"vocab.txt: 100%"}},"f8a7a26a303e441b9e904a2c16f25a54":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa39098a82c84fbdb9b747ecd91b9aed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49ccfdc933ae416293b3ead357abdef2","placeholder":"​","style":"IPY_MODEL_3403c9cec4784bfea5231cab0cf165a8","value":" 466k/466k [00:00&lt;00:00, 3.44MB/s]"}},"fc011fc9aca44c4c9c89828a9cfc3b23":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":4}
